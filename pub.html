<html>
    <head>
        <link rel="stylesheet" type="text/css" href="assets/font-awesome-4.7.0/css/font-awesome.min.css">
        <link rel="stylesheet" type="text/css" href="assets/academicons-1.8.6/css/academicons.min.css">
        <!-- <link rel="stylesheet" type="text/css" href="assets/bootstrap-4.3.1-dist/css/bootstrap.min.css"> -->
        <link rel="stylesheet" type="text/css" href="assets/style.css">
        <link rel="icon" type="image/png" href="assets/figures/icon.png">
        <link rel="apple-touch-icon" type="image/png" href="assets/figures/large-icon.png">
        <!-- <link rel="stylesheet" href="font.css"> -->
        <title>Xian Liu's Homepage </title>
    </head>
    
    <body><table border=0 width=1000px align=center><tr><td>
    
        <td valign="top">

        <br>
        <table style="font-size: 11pt;" border=0 width=100%>
          <tr>
            <td> 
                  <p style="text-align:center;font-size: 25pt;">
                    <name>Xian Liu</name>
                    <!-- <br><br><br> -->
                  </p>
                <font face="helvetica, ariel, 'sans serif'" size="4"> 
                    Research Scientist<br>
                    NVIDIA Research<br>
                    Santa Clara, CA<br><br>
                    <a style="font-size: 13pt" href="mailto:alvinliu0430@gmail.com">E-mail</a> &nbsp/&nbsp
                    <a style="font-size: 13pt" href="https://alvinliu0.github.io/misc/CV_Xian_Liu_Public_Version.pdf">CV</a> &nbsp/&nbsp
                    <a style="font-size: 13pt" href="https://scholar.google.com/citations?hl=en&user=QHx5ncgAAAAJ">Google Scholar</a> &nbsp/&nbsp
                    <a style="font-size: 13pt" href="https://github.com/alvinliu0"> Github </a> &nbsp/&nbsp
                    <a style="font-size: 13pt" href="https://twitter.com/AlvinLiu27"> Twitter </a> &nbsp/&nbsp
                    <a style="font-size: 13pt" href="https://www.linkedin.com/in/xian-liu-9840b52a3/"> LinkedIn </a>
                </font>
            </td>
            <td width = "30%">
                <img width=250 src="images/me.jpg" border="0">
                    </td>
        </tr>
      </table> 



        <h2>Full Publications [<a style="font-size: 15pt" href="./index.html"> Home </a>] <font color="black" size="2">(* indicates equal contribution)</font> </h2>
        <table style="border-collapse:separate; border-spacing:0px 35px;" cellspacing="8">
          <tbody>

            <tr>
              <td width="23%">
                <img width="180" height="100" style="padding: 0px 10px 0px 10px; margin-right: 25px;" src="./images/cosmos1.gif">
              </td>
              <td>
                <div class="title">
                  Cosmos World Foundation Model Platform for Physical AI
                </div>
                <div class="author">
                  <a style="font-size: 12pt" href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a>: <span class="me"><u>Xian Liu</u> (Core Contributor)</span>.
                </div>
                <div class="conf">
                  Contributions: Auto-Regressive Foundation Model Pre-Training & Post-Training. <font color="red"> (CES'25 Best of AI, Best Overall)</font>
                </div>
                <div>
                  <span class="tag"> <a href="https://www.nvidia.com/en-us/ai/cosmos/" target="_blank">Webpage</a> </span> /
                  <span class="tag"> <a href="https://research.nvidia.com/labs/dir/cosmos1/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2501.03575" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://blogs.nvidia.com/blog/cosmos-world-foundation-models/" target="_blank">Blog</a> </span> /
                  <span class="tag"> <a href="https://github.com/NVIDIA/Cosmos" target="_blank">Github</a> </span> /
                  <span class="tag"> <a href="https://huggingface.co/collections/nvidia/cosmos-6751e884dc10e013a0a0d8e6" target="_blank">HuggingFace</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=9Uch931cDx8" target="_blank">Demo</a> </span> /
                  <span class="tag"> <a href="https://build.nvidia.com/explore/discover" target="_blank">Preview</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/live/k82RwXqZHY8?t=3303s" target="_blank">Keynote (Jensen Huang, CES'25)</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="80" style="padding: 10px 0px 10px 0px; margin-right: 25px;" src="./images/tokenizer.jpg">
              </td>
              <td>
                <div class="title">
                  Cosmos Tokenizer: A Suite of Image and Video Neural Tokenizers
                </div>
                <div class="author">
                  <a style="font-size: 12pt" href="https://www.nvidia.com/en-us/research/">NVIDIA Research</a>: <span class="me"><u>Xian Liu</u> (Core Contributor)</span>.
                </div>
                <div class="conf">
                  Contributions: Continuous/Discrete Image/Video Tokenizers.
                </div>
                <div>
                  <span class="tag"> <a href="https://research.nvidia.com/labs/dir/cosmos-tokenizer" target="_blank">Webpage</a> </span> /
                  <span class="tag"> <a href="https://research.nvidia.com/labs/dir/cosmos-tokenizer" target="_blank">Technical Report</a> </span> /
                  <span class="tag"> <a href="https://developer.nvidia.com/blog/state-of-the-art-multimodal-generative-ai-model-development-with-nvidia-nemo/" target="_blank">Blog</a> </span> /
                  <span class="tag"> <a href="https://github.com/NVIDIA/Cosmos-Tokenizer" target="_blank">Github</a> </span> /
                  <span class="tag"> <a href="https://huggingface.co/collections/nvidia/cosmos-tokenizer-672b93023add81b66a8ff8e6" target="_blank">HuggingFace</a> </span> /
                  <span class="tag"> <a href="https://youtu.be/Soy_myOfWIU" target="_blank">Demo</a> </span> /
                  <span class="tag"> <a href="https://github.com/NVlabs/TokenBench" target="_blank">Benchmark</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="125" style="padding: 0px 0px 0px 0px" src="./images/3dtrajmaster.gif">
              </td>
              <td>
                <div class="title">
                  3DTrajMaster: Mastering 3D Trajectory for Multi-Entity Motion in Video Generation
                </div>
                <div class="author">
                  <a href="https://fuxiao0719.github.io/">Xiao Fu</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://xinntao.github.io/">Xintao Wang</a>,
                  <a href="https://pengsida.net/">Sida Peng</a>,
                  <a href="https://menghanxia.github.io/">Menghan Xia</a>,
                  <a href="https://xiaoyushi97.github.io/">Xiaoyu Shi</a>,
                  <a href="https://scholar.google.ru/citations?user=fWxWEzsAAAAJ&hl=en">Ziyang Yuan</a>,
                  <a href="https://scholar.google.com/citations?user=P6MraaYAAAAJ&hl=en">Pengfei Wan</a>,
                  <a href="https://openreview.net/profile?id=~Di_ZHANG3">Di Zhang</a>,
                  <a href="http://dahua.site/">Dahua Lin</a>.
                </div>
                <div class="conf">
                  International Conference on Learning Representations (<b>ICLR</b>), 2025.
                </div>
                <div>
                  <span class="venue"> <a href="https://iclr.cc/Conferences/2025">ICLR 2025</a> </span> /
                  <span class="tag"> <a href="https://openreview.net/forum?id=Gx04TnVjee" target="_blank">OpenReview</a> </span> /
                  <span class="tag"> <a href="http://fuxiao0719.github.io/projects/3dtrajmaster" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/kwaiVGI/3DTrajMaster" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2412.07759" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://huggingface.co/datasets/KwaiVGI/360Motion-Dataset" target="_blank">Dataset</a>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="125" style="padding: 0px 0px 0px 0px" src="./images/videovae.png">
              </td>
              <td>
                <div class="title">
                  High-Quality Joint Image and Video Tokenization with Causal VAE
                </div>
                <div class="author">
                  <a href="https://dawitmureja.github.io/">Dawit Mureja Argaw</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://qsh-zh.github.io/">Qinsheng Zhang</a>,
                  <a href="https://scholar.google.co.uk/citations?user=JJ_LQ0YAAAAJ&hl=en">Joon Son Chung</a>,
                  <a href="http://mingyuliu.net/">Ming-Yu Liu</a>,
                  <a href="https://fitsumreda.github.io/">Fitsum Reda</a>.
                </div>
                <div class="conf">
                  International Conference on Learning Representations (<b>ICLR</b>), 2025.
                </div>
                <div>
                  <span class="venue"> <a href="https://iclr.cc/Conferences/2025">ICLR 2025</a> </span> /
                  <span class="tag"> <a href="https://openreview.net/forum?id=aRD1NqcXTC" target="_blank">OpenReview</a> </span>
                </div>
              </td>
            </tr>
            
            <tr>
              <td width="23%">
                <img width="200" height="125" style="padding: 0px 0px 0px 0px" src="./images/sjd.png">
              </td>
              <td>
                <div class="title">
                  Accelerating Auto-regressive Text-to-Image Generation with Training-free Speculative Jacobi Decoding
                </div>
                <div class="author">
                  <a href="https://tyshiwo1.github.io/">Yao Teng</a>,
                  Han Shi,
                  <span class="me"><u>Xian Liu</u></span>,
                  Xuefei Ning,
                  Guohao Dai,
                  Yu Wang,
                  Zhenguo Li,
                  <a href="https://xh-liu.github.io/">Xihui Liu</a>.
                </div>
                <div class="conf">
                  International Conference on Learning Representations (<b>ICLR</b>), 2025.
                </div>
                <div>
                  <span class="venue"> <a href="https://iclr.cc/Conferences/2025">ICLR 2025</a> </span> /
                  <span class="tag"> <a href="https://openreview.net/forum?id=LZfjxvqw0N" target="_blank">OpenReview</a> </span> /
                  <span class="tag"> <a href="https://github.com/tyshiwo1/Accelerating-T2I-AR-with-SJD" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2410.01699" target="_blank">arXiv</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="180" height="125" style="padding: 0px 10px 0px 10px" src="./images/edgerunner.png">
              </td>
              <td>
                <div class="title">
                  EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation
                </div>
                <div class="author">
                  <a href="https://me.kiui.moe/">Jiaxiang Tang</a>,
                  <a href="https://mli0603.github.io/">Zhaoshuo Li</a>,
                  <a href="https://zekunhao.com/">Zekun Hao</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://scholar.google.com/citations?user=RuHyY6gAAAAJ">Gang Zeng</a>,
                  <a href="https://mingyuliu.net/">Ming-Yu Liu</a>,
                  <a href="https://qsh-zh.github.io/">Qinsheng Zhang</a>.
                </div>
                <div class="conf">
                  International Conference on Learning Representations (<b>ICLR</b>), 2025.
                </div>
                <div>
                  <span class="venue"> <a href="https://iclr.cc/Conferences/2025">ICLR 2025</a> </span> /
                  <span class="tag"> <a href="https://openreview.net/forum?id=81cta3WQVI" target="_blank">OpenReview</a> </span> /
                  <span class="tag"> <a href="https://research.nvidia.com/labs/dir/edgerunner/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/NVlabs/EdgeRunner" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2409.18114" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://github.com/NVlabs/EdgeRunner/tree/main/meto" target="_blank">Mesh Tokenizer</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="125" style="padding: 0px 0px 0px 0px" src="./images/motioncraft.gif">
              </td>
              <td>
                <div class="title">
                  MotionCraft: Crafting Whole-Body Motion with Plug-and-Play Multimodal Controls
                </div>
                <div class="author">
                  <a href="https://yxbian23.github.io/">Yuxuan Bian</a>,
                  <a href="https://ailingzeng.site/">Ailing Zeng</a>,
                  <a href="https://juxuan27.github.io/">Xuan Ju</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://zzyfd.github.io/">Zhaoyang Zhang</a>,
                  <a href="https://sites.google.com/view/cuweiliu">Wei Liu</a>,
                  <a href="https://github.com/cure-lab">Qiang Xu</a>.
                </div>
                <div class="conf">
                  AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2025.
                </div>
                <div>
                  <span class="venue"> <a href="https://aaai.org/conference/aaai/aaai-25/">AAAI 2025</a> </span> /
                  <span class="tag"> <a href="https://cure-lab.github.io/MotionCraft/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/cure-lab/MotionCraft" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://cure-lab.github.io/MotionCraft/assets/img/1-min-demo.mp4" target="_blank">Demo</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2407.21136" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://github.com/cure-lab/MotionCraft?tab=readme-ov-file#data-download-%EF%B8%8F" target="_blank">Dataset</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="125" src="./images/tc4d.gif">
              </td>
              <td>
                <div class="title">
                  TC4D: Trajectory-Conditioned Text-to-4D Generation
                </div>
                <div class="author">
                  <a href="https://sherwinbahmani.github.io/">Sherwin Bahmani*</a>,
                  <span class="me"><u>Xian Liu*</u></span>,
                  <a href="https://yifita.netlify.app/">Yifan Wang*</a>,
                  <a href="https://universome.github.io/">Ivan Skorokhodov</a>,
                  <a href="https://www.lessvrong.com/">Victor Rong</a>,
                  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>,
                  <a href="https://xh-liu.github.io/">Xihui Liu</a>,
                  <a href="https://jjparkcv.github.io/">Jeong Joon Park</a>,
                  <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>,
                  <a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a>,
                  <a href="https://taiya.github.io/">Andrea Tagliasacchi</a>,
                  <a href="https://davidlindell.com/">David B. Lindell</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2024.
                </div>
                <div>
                  <span class="venue"> <a href="https://eccv2024.ecva.net/">ECCV 2024</a> </span> /
                  <span class="tag"> <a href="https://sherwinbahmani.github.io/tc4d/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2403.17920" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://github.com/sherwinbahmani/tc4d" target="_blank">Github</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="125" src="./images/brushnet.png">
              </td>
              <td>
                <div class="title">
                  BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion
                </div>
                <div class="author">
                  <a href="https://juxuan27.github.io/">Xuan Ju</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://xinntao.github.io/">Xintao Wang</a>,
                  <a href="https://scholar.google.com/citations?hl=en-us&user=HzemVzoAAAAJ">Yuxuan Bian</a>,
                  <a href='https://scholar.google.com/citations?user=4oXBp9UAAAAJ'>Ying Shan</a>,
                  <a href="https://www.cse.cuhk.edu.hk/~qxu/">Qiang Xu</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2024.
                </div>
                <div>
                  <span class="venue"> <a href="https://eccv2024.ecva.net/">ECCV 2024</a> </span> /
                  <span class="tag"> <a href="https://tencentarc.github.io/BrushNet/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2403.06976" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://drive.google.com/file/d/1IkEBWcd2Fui2WHcckap4QFPcCI0gkHBh/view" target="_blank">Demo Video</a> </span> /
                  <span class="tag"> <a href="https://forms.gle/9TgMZ8tm49UYsZ9s5" target="_blank">Dataset</a> </span> /
                  <span class="tag"> <a href="https://github.com/TencentARC/BrushNet" target="_blank">Github</a> </span> /
                  <span class="tag"> <a href="https://huggingface.co/spaces/TencentARC/BrushNet" target="_blank">HuggingFace Demo</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%" valign="middle">
                <img width="200" height="80" style="padding: 22.5px 0px 22.5px 0px" src="./images/e2gan.png">
              </td>
              <td>
                <div class="title">
                  E<sup>2</sup>GAN: Efficient Training of Efficient GANs for Image-to-Image Translation
                </div>
                <div class="author">
                  <a href="https://yifanfanfanfan.github.io/">Yifan Gong</a>, 
                  <a href="https://zhanzheng8585.github.io/">Zheng Zhan</a>, 
                  <a href="https://scholar.google.com/citations?user=X9iggBcAAAAJ&hl=en-us">Qing Jin</a>, 
                  <a href="https://scholar.google.com/citations?user=XUj8koUAAAAJ&hl=en">Yanyu Li</a>,
                  <a href='https://scholar.google.com/citations?user=nAaroNMAAAAJ'>Yerlan Idelbayev</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href='https://www.linkedin.com/in/asmekal/'>Andrey Zharkov</a>, 
                  <a href='https://kfiraberman.github.io/'>Kfir Aberman</a>, 
                  <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>,
                  <a href="https://web.northeastern.edu/yanzhiwang/">Yanzhi Wang</a>,
                  <a href="https://alanspike.github.io/">Jian Ren</a>.           
                </div>
                <div class="conf">
                  International Conference on Machine Learning (<b>ICML</b>), 2024.
                </div>
                <div>
                  <span class="venue"> <a href="https://icml.cc/Conferences/2024">ICML 2024</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2401.06127.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2401.06127" target="_blank">arXiv</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="180" height="125" style="padding: 0px 10px 0px 10px" src="./images/humangaussian-teaser.gif">
              </td>
              <td>
                <div class="title">
                  HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting
                </div>
                <div class="author">
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://xiaohangzhan.github.io/">Xiaohang Zhan</a>,
                  <a href="https://me.kiui.moe/">Jiaxiang Tang</a>,
                  <a href='https://scholar.google.com/citations?user=4oXBp9UAAAAJ'>Ying Shan</a>,
                  <a href="https://scholar.google.com/citations?user=RuHyY6gAAAAJ">Gang Zeng</a>,
                  <a href="http://dahua.site/">Dahua Lin</a>,
                  <a href="https://xh-liu.github.io/">Xihui Liu</a>,
                  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>.
                </div>
                <div class="conf">
                  IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024. <font color="red"> (Highlight, Top 2.8%)</font>
                </div>
                <div>
                  <span class="venue"> <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/HumanGaussian" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/HumanGaussian/humangaussian.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2311.17061" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=S3djzHoqPKY" target="_blank">Demo Video</a> </span> /
                  <span class="tag"> <a href="https://github.com/alvinliu0/HumanGaussian" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://github.com/alvinliu0/HumanGaussian#pretrained-models" target="_blank">Models</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%" valign="middle">
                <img width="200" height="125" src="./images/textcrafter.png">
              </td>
              <td>
                <div class="title">
                  TextCraftor: Your Text Encoder Can be Image Quality Controller
                </div>
                <div class="author">
                  <a href="https://scholar.google.com/citations?user=XUj8koUAAAAJ&hl=en">Yanyu Li</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://anilkagak2.github.io/">Anil Kag</a>,
                  <a href="https://www.linkedin.com/in/erichuju">Ju Hu</a>,
                  <a href='https://scholar.google.com/citations?user=nAaroNMAAAAJ'>Yerlan Idelbayev</a>,
                  <a href="https://www.linkedin.com/in/dhritiman-sagar-5775169/">Dhritiman Sagar</a>,
                  <a href="https://web.northeastern.edu/yanzhiwang/">Yanzhi Wang</a>,
                  <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>,
                  <a href="https://alanspike.github.io/">Jian Ren</a>.
                </div>
                <div class="conf">
                  IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024.
                </div>
                <div>
                  <span class="venue"> <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a> </span> /
                  <span class="tag"> <a href="https://snap-research.github.io/textcraftor/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/snap-research/textcraftor" target="_blank">Code</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2403.18978.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2403.18978" target="_blank">arXiv</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="180" height="125" style="padding: 0px 10px 0px 10px" src="./images/hyperhuman.png">
              </td>
              <td>
                <div class="title">
                  HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion
                </div>
                <div class="author">
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://alanspike.github.io/">Jian Ren</a>,
                  <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>,
                  <a href='https://universome.github.io/'>Ivan Skorokhodov</a>,
                  <a href="https://scholar.google.com/citations?user=XUj8koUAAAAJ&hl=en">Yanyu Li</a>,
                  <a href="http://dahua.site/">Dahua Lin</a>,
                  <a href="https://xh-liu.github.io/">Xihui Liu</a>,
                  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>,
                  <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>.
                </div>
                <div class="conf">
                  International Conference on Learning Representations (<b>ICLR</b>), 2024. <font color="red"> (Review Score 6, 6, 8, 10, Top 1.6%, <a style="font-size: 12pt" href="https://papercopilot.com/statistics/iclr-statistics/iclr-2024-statistics/">Rank</a>)</font>
                </div>
                <div>
                  <span class="venue"> <a href="https://iclr.cc/Conferences/2024">ICLR 2024</a> </span> /
                  <span class="tag"> <a href="https://openreview.net/forum?id=duyA42HlCK" target="_blank">OpenReview</a> </span> /
                  <span class="tag"> <a href="https://snap-research.github.io/HyperHuman/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://snap-research.github.io/HyperHuman/content/hyperhuman.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/abs/2310.08579" target="_blank">arXiv</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=eRPZW1pwxog" target="_blank">Short Demo (3min)</a> </span> /
                  <span class="tag"> <a href="https://www.youtube.com/watch?v=CxGfbwZOcyU" target="_blank">Long Demo (10min)</a> </span> /
                  <span class="tag"> <a href="https://github.com/snap-research/HyperHuman" target="_blank">Github</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="80" style="padding: 22.5px 0px 22.5px 0px" src="./images/iccv23.png">
              </td>
              <td>
                <div class="title">
                  Semantics Meets Temporal Correspondence: Self-supervised Object-centric Learning in Videos
                </div>
                <div class="author">
                  <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>,
                  Shuangrui Ding,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="http://dahua.site/">Dahua Lin</a>.
                </div>
                <div class="conf">
                  International Conference on Computer Vision (<b>ICCV</b>), 2023.
                </div>
                <div>
                  <span class="venue"> <a href="https://iccv2023.thecvf.com/">ICCV 2023</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2308.09951.pdf" target="_blank">Paper</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="80" style="padding: 22.5px 0px 22.5px 0px" src="./images/miccai23.png">
              </td>
              <td>
                <div class="title">
                  Make-A-Volume: Leveraging Latent Diffusion Models for Cross-Modality 3D Brain MRI Synthesis
                </div>
                <div class="author">
                  <a href="https://scholar.google.com/citations?user=TPD_P98AAAAJ&hl=zh-CN">Lingting Zhu</a>,
                  Zeyue Xue, 
                  Zhenchao Jin, 
                  <span class="me"><u>Xian Liu</u></span>,
                  Jingzhen He,
                  Xuanyu Liu,
                  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>,
                  <a href="https://yulequan.github.io/">Lequan Yu</a>.
                </div>
                <div class="conf">
                  Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2023.
                </div>
                <div>
                  <span class="venue"> <a href="https://conferences.miccai.org/2023/en/">MICCAI 2023</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2307.10094.pdf" target="_blank">Paper</a> </span>
                </div>
              </td>
            </tr>

            <td width="23%">
              <img width="200" height="80" style="padding: 22.5px 0px 22.5px 0px" src="./images/diffgesture.png">
            </td>
            <td>
              <div class="title">
                Taming Diffusion Models for Audio-Driven Co-Speech Gesture Generation
              </div>
              <div class="author">
                <span class="me"><u>Xian Liu*</u></span>,
                <a href="https://scholar.google.com/citations?user=TPD_P98AAAAJ&hl=zh-CN">Lingting Zhu*</a>,
                Xuanyu Liu,
                <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>,
                <a href="https://liuziwei7.github.io/">Ziwei Liu</a>,
                <a href="https://yulequan.github.io/">Lequan Yu</a>.
              </div>
              <div class="conf">
                IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.
              </div>
              <div>
                <span class="venue"> <a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> </span> /
                <span class="tag"> <a href="https://arxiv.org/pdf/2303.09119.pdf" target="_blank">Paper</a> </span> /
                <span class="tag"> <a href="https://github.com/Advocate99/DiffGesture" target="_blank">Code</a> </span>
              </div>
            </td>
          </tr>

            <tr>
              <td width="23%">
                <img width="200" height="80" style="padding: 22.5px 0px 22.5px 0px" src="./images/monohuman.png">
              </td>
              <td>
                <div class="title">
                  MonoHuman: Animatable Human Neural Field from Monocular Video
                </div>
                <div class="author">
                  <a href="https://yzmblog.github.io/">Zhengming Yu</a>,
                  Wei Cheng,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://wywu.github.io/">Wayne Wu</a>,
                  <a href="https://kwanyeelin.github.io/">Kwan-Yee Lin</a>.
                </div>
                <div class="conf">
                  IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.
                </div>
                <div>
                  <span class="venue"> <a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2304.02001.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://yzmblog.github.io/projects/MonoHuman/" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/Yzmblog/MonoHuman" target="_blank">Code</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="100" style="padding: 12.5px 0px 12.5px 0px" src="images/mol_tmlr.png" border="0">
                      </td>
              <td>
              <div class="title">ChemSpacE: Interpretable and Interactive Chemical Space Exploration</div>
            
              <div class="author">
                  <a href='https://yuanqidu.github.io/'>Yuanqi Du</a>, 
                  <span class="me"><u>Xian Liu</u></span>, 
                  Shengchao Liu, 
                  Jieyu Zhang, 
                  <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>.
              </div>
              <div class="conf">
                Transactions on Machine Learning Research (<b>TMLR</b>), 2023.
              </div>
              <div>
                  <span class="venue"> <a href="https://jmlr.org/tmlr/">TMLR 2023</a> </span> /
                  <span class="tag"> <a href="https://openreview.net/pdf?id=C1Xl8dYCBn">Paper</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/molspace_poster_ICLR.pdf">Poster</a> </span>
              </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="100" style="padding: 12.5px 0px 12.5px 0px" src="./images/angie.png">
              </td>
              <td>
                <div class="title">
                  Audio-Driven Co-Speech Gesture Video Generation
                </div>
                <div class="author">
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://wuqianyi.top/">Qianyi Wu</a>,
                  <a href="https://hangz-nju-cuhk.github.io/">Hang Zhou</a>,
                  <a href='https://yuanqidu.github.io/'>Yuanqi Du</a>,
                  <a href="https://wywu.github.io/">Wayne Wu</a>,
                  <a href="http://dahua.site/">Dahua Lin</a>,
                  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>.
                </div>
                <div class="conf">
                  Advances in Neural Information Processing Systems (<b>NeurIPS</b>), 2022. <font color="red"> (Spotlight, Top 5%)</font>
                </div>
                <div>
                  <span class="venue"> <a href="https://neurips.cc/">NeurIPS 2022</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2212.02350.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/ANGIE" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/alvinliu0/ANGIE" target="_blank">Code</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="100" style="padding: 12.5px 0px 12.5px 0px" src="./images/SSP-NeRF.png">
              </td>
              <td>
                <div class="title">
                  Semantic-Aware Implicit Neural Audio-Driven Video Portrait Generation
                </div>
                <div class="author">
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://justimyhxu.github.io/">Yinghao Xu</a>,
                  <a href="https://wuqianyi.top/">Qianyi Wu</a>,
                  <a href="https://hangz-nju-cuhk.github.io/">Hang Zhou</a>,
                  <a href="https://wywu.github.io/">Wayne Wu</a>,
                  <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2022. <font color="red"> (Oral, Top 2.7%)</font>
                </div>
                <div>
                  <span class="venue"> <a href="https://eccv2022.ecva.net/">ECCV 2022</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2201.07786.pdf" target="_blank">Paper</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/SSP-NeRF" target="_blank">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/alvinliu0/SSP-NeRF" target="_blank">Code</a> </span>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="80" style="padding: 22.5px 0px 22.5px 0px" src="images/mol_iclrw.png" border="0">
                      </td>
              <td>
              <div class="title">ChemSpacE: Toward Steerable and Interpretable Chemical Space Exploration</div>
            
              <div class="author">
                  <a href='https://yuanqidu.github.io/'>Yuanqi Du</a>, 
                  <span class="me"><u>Xian Liu</u></span>, 
                  Shengchao Liu, 
                  Jieyu Zhang, 
                  <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>.
              </div>
              <div class="conf">
                International Conference on Learning Representations (<b>ICLR</b>) Workshop, 2022.
              </div>
              <div class="conf">
                Also appears at ELLIS 2021 MLMD Workshop. <font color="red"> (Oral, Top 5%)</font>
              </div>
              <div>
                  <span class="venue"> <a href="https://iclr.cc/Conferences/2022">ICLR 2022</a> </span> /
                  <span class="tag"> <a href="https://openreview.net/pdf?id=VELTk5U1Fku">Paper</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/molspace_poster_ICLR.pdf">Poster</a> </span>
              </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="125" src="./images/objsdf.png">
              </td>
              <td>
                <div class="title">
                  Object-Compositional Neural Implicit Surfaces
                </div>
                <div class="author">
                  <a href="https://wuqianyi.top/">Qianyi Wu</a>,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://donydchen.github.io/">Yuedong Chen</a>,
                  <a href="https://likojack.github.io/kejieli/#/home">Kejie Li</a>,
                  <a href="https://www.chuanxiaz.com/">Chuanxia Zheng</a>,
                  <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>,
                  <a href="http://www.ntu.edu.sg/home/asjmzheng/">Jianmin Zheng</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2022.
                </div>
                <div>
                  <div>
                    <span class="venue"> <a href="https://eccv2022.ecva.net/">ECCV 2022</a> </span> /
                    <span class="tag"> <a href="http://arxiv.org/pdf/2207.09686.pdf" target="_blank">Paper</a> </span> /
                    <span class="tag"> <a href="https://qianyiwu.github.io/objectsdf/" target="_blank">Project</a> </span> /
                    <span class="tag"> <a href="https://github.com/QianyiWu/objsdf" target="_blank">Code</a> </span>
                  </div>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="100" style="padding: 12.5px 0px 12.5px 0px" src="./images/qian2022static.png">
              </td>
              <td>
                <div class="title">
                  Static and Dynamic Concepts for Self-supervised Video Representation Learning
                </div>
                <div class="author">
                  <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>,
                  Shuangrui Ding,
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="http://dahua.site/">Dahua Lin</a>.
                </div>
                <div class="conf">
                  European Conference on Computer Vision (<b>ECCV</b>), 2022.
                </div>
                <div>
                  <div>
                    <span class="venue"> <a href="https://eccv2022.ecva.net/">ECCV 2022</a> </span> /
                    <span class="tag"> <a href="https://arxiv.org/pdf/2207.12795.pdf" target="_blank">Paper</a> </span> /
                    <span class="tag"> <a href="https://github.com/shvdiwnkozbw/Self-supervised-Video-Concept" target="_blank">Code</a> </span>
                  </div>
                </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="100" style="padding: 12.5px 0px 12.5px 0px" src="./images/HA2G.png">
              </td>
              <td>
                <div class="title">
                  Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation
                </div>
                <div class="author">
                  <span class="me"><u>Xian Liu</u></span>,
                  <a href="https://wuqianyi.top/">Qianyi Wu</a>,
                  <a href="https://hangz-nju-cuhk.github.io/">Hang Zhou</a>,
                  <a href="https://justimyhxu.github.io/">Yinghao Xu</a>,
                  <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>,
                  <a href="https://alvinliu0.github.io/">Xinyi Lin</a>,
                  <a href="https://xzhou.me/">Xiaowei Zhou</a>,
                  <a href="https://wywu.github.io/">Wayne Wu</a>,
                  <a href="http://daibo.info/">Bo Dai</a>,
                  <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>.
                  <!-- <span style="font-size: 11pt;" class="me">Xian Liu</span>,
                  <a style="font-size: 10.8pt;" href="https://wuqianyi.top/">Qianyi Wu</a>,
                  <a style="font-size: 10.8pt;" href="https://hangz-nju-cuhk.github.io/">Hang Zhou</a>,
                  <a style="font-size: 10.8pt;" href="https://justimyhxu.github.io/">Yinghao Xu</a>,
                  <a style="font-size: 10.8pt;" href="https://shvdiwnkozbw.github.io/">Rui Qian</a>,
                  <a style="font-size: 10.8pt;" href="https://alvinliu0.github.io/">Xinyi Lin</a>,
                  <a style="font-size: 10.8pt;" href="https://xzhou.me/">Xiaowei Zhou</a>,
                  <a style="font-size: 10.8pt;" href="https://wywu.github.io/">Wayne Wu</a>,
                  <a style="font-size: 10.8pt;" href="http://daibo.info/">Bo Dai</a>,
                  <a style="font-size: 10.8pt;" href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>. -->
                </div>
                <div class="conf">
                  IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2022.
                </div>
                <div class="conf">
                  Also appears at CVPR 2022 <a href="https://sightsound.org/">Sight and Sound Workshop</a>. [5-min Invited Talk] <a href="https://drive.google.com/file/d/1oAJ863xFtY4ycZmZOtFD_0DYHfCH8w6T/view?usp=sharing">(link)</a> 
                </div>
                <div>
                  <!-- <span class="venue"> <a href="">ArXiv pre-print</a> </span> / -->
                  <span class="venue"> <a href="http://cvpr2022.thecvf.com/">CVPR 2022</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2203.13161.pdf">Paper</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/HA2G/HA2G_poster.pdf">Poster</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/HA2G">Project</a> </span> /
                  <span class="tag"> <a href="https://github.com/alvinliu0/HA2G">Code</a> </span>
              </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="125" src="images/ier.png" border="0">
                      </td>
              <td>
              <div class="title">Visual Sound Localization in the Wild by Cross-Modal Interference Erasing</div>
            
              <div class="author">
                  <span class="me"><u>Xian Liu*</u></span>, 
                  <a href='https://shvdiwnkozbw.github.io/'>Rui Qian*</a>, 
                  <a href='https://hangz-nju-cuhk.github.io/'>Hang Zhou*</a>, 
                  <a href="https://dtaoo.github.io/">Di Hu</a>, 
                  <a href="https://weiyaolin.github.io/">Weiyao Lin</a>,
                  <a href="https://liuziwei7.github.io/">Ziwei Liu</a>, 
                  <a href="http://bzhou.ie.cuhk.edu.hk/">Bolei Zhou</a>, 
                  <a href="https://xzhou.me/">Xiaowei Zhou</a>.
              </div>
              <div class="conf">
                AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2022.
              </div>
              <div>
                  <span class="venue"> <a href="https://aaai.org/Conferences/AAAI-22/">AAAI 2022</a> </span> /
                  <span class="tag"> <a href="https://arxiv.org/pdf/2202.06406.pdf">Paper</a> </span> /
                  <span class="tag"> <a href="https://alvinliu0.github.io/projects/ier_poster.pdf">Poster</a> </span>
              </div>
              </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="100" style="padding: 12.5px 0px 12.5px 0px" src="images/iccv.png" border="0">
                        </td>
                <td>
                <div class="title">Enhancing Self-supervised Video Representation Learning via Multi-level Feature Optimization</div>
                <div class="author">
                  <a href="https://shvdiwnkozbw.github.io/">Rui Qian</a>,
                  Yuxi Li,
                  Huabin Liu,
                  John See,
                  Shuangrui Ding, 
                  <span class="me"><u>Xian Liu</u></span>, 
                  Dian Li,
                  <a href="https://weiyaolin.github.io/">Weiyao Lin</a>.
                </div>
                <div class="conf">
                  International Conference on Computer Vision (<b>ICCV</b>), 2021.
                </div>
                <div>
                    <span class="venue"> <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a> </span> /
                    <span class="tag"> <a href="https://arxiv.org/pdf/2108.02183.pdf">Paper</a> </span> /
                    <span class="tag"> <a href="https://github.com/shvdiwnkozbw/Video-Representation-via-Multi-level-Optimization">Code</a> </span>
                </div> 
                </td>
            </tr>

            <tr>
              <td width="23%">
                <img width="200" height="100" style="padding: 12.5px 0px 12.5px 0px" src="images/mocap.png" border="0">
                      </td>
              <td>
              <div class="title">Motion Capture from Internet Videos</div>
              <div class="author">
                <a href="https://jtdong.com/">Junting Dong</a>,
                Qing Shuai,
                Yuanqing Zhang,
                <span class="me"><u>Xian Liu</u></span>, 
                <a href="https://xzhou.me/">Xiaowei Zhou</a>,
                <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>.
              </div>
              <div class="conf">
                European Conference on Computer Vision (<b>ECCV</b>), 2020. <font color="red"> (Oral, Top 2%)</font>
              </div>
              <div>
                <span class="venue"> <a href="https://eccv2020.eu/">ECCV 2020</a> </span> /
                <span class="tag"> <a href="https://arxiv.org/pdf/2008.07931.pdf">Paper</a> </span> /
                <span class="tag"> <a href="https://zju3dv.github.io/iMoCap/">Project</a> </span> /
                <span class="tag"> <a href="https://github.com/zju3dv/EasyMocap">Code</a> </span>
              </div> 
              </td>
          </tr>
          </tbody>        
          </table>
            
            </body>
</html>
